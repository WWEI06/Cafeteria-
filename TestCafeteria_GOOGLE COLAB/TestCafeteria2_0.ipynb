{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3pcYIGusrpT"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate==0.21.0 transformers==4.31.0 tokenizers==0.13.3\n",
        "!pip install bitsandbytes==0.40.0 einops==0.6.1\n",
        "!pip install xformers==0.0.22.post7\n",
        "!pip install langchain==0.1.4\n",
        "!pip install faiss-gpu==1.7.1.post3\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda, bfloat16\n",
        "import transformers\n",
        "\n",
        "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
        "\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# set quantization configuration to load large model with less GPU memory\n",
        "# this requires the `bitsandbytes` library\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")\n",
        "\n",
        "# begin initializing HF items, you need an access token\n",
        "hf_auth = 'huggingfacetoken_id'\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        "    token=hf_auth\n",
        ")\n",
        "\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto',\n",
        "    token=hf_auth\n",
        ")\n",
        "\n",
        "# enable evaluation mode to allow model inference\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded on {device}\")"
      ],
      "metadata": {
        "id": "UzA7ckWM63kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth\n",
        ")"
      ],
      "metadata": {
        "id": "sRh5O3i67HQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
        "stop_token_ids"
      ],
      "metadata": {
        "id": "szEVx_ga7Lrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "# define custom stopping criteria object\n",
        "class StopOnTokens(StoppingCriteria):\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop_ids in stop_token_ids:\n",
        "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
      ],
      "metadata": {
        "id": "8xQff4lLskua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,  # langchain expects the full text\n",
        "    task='text-generation',\n",
        "    # we pass model parameters here too\n",
        "    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
        "    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
        "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
        "    repetition_penalty=1.1  # without this output begins repeating\n",
        ")"
      ],
      "metadata": {
        "id": "D4PR7lI-snaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = generate_text(\"Explain me the difference between Data Lakehouse and Data Warehouse.\")\n",
        "print(res[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "u9fXISAhsuVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# checking again that everything is working fine\n",
        "llm(prompt=\"Explain me the difference between Data Lakehouse and Data Warehouse.\")"
      ],
      "metadata": {
        "id": "jImFQRoMs0X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "web_links = [\"https://www.uts.edu.my/about-university/\",\"https://en.wikipedia.org/wiki/University_of_Technology_Sarawak\", \"https://www.uts.edu.my/school/\", \"https://scm.uts.edu.my/programme/undergraduate-programme/bachelor-of-computer-science/\", \"https://www.uts.edu.my/management-team/\", \"https://www.uts.edu.my/facility/\", \"https://www.uts.edu.my/tuition-fees/\"]\n",
        "\n",
        "loader = WebBaseLoader(web_links)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "WrLmhv1ws2p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "s_xfDsjrs6Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
        "\n",
        "# storing embeddings in the vector store\n",
        "vectorstore = FAISS.from_documents(all_splits, embeddings)"
      ],
      "metadata": {
        "id": "SgzrSe-ws75v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)"
      ],
      "metadata": {
        "id": "llSI0zS2tD67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "query = \"ucts is uts?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])\n",
        "print(chat_history)"
      ],
      "metadata": {
        "id": "6GS3grtrtGmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = [(query, result[\"answer\"])]\n",
        "\n",
        "query = \"what is full name of ucts and uts?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])\n",
        "print(chat_history)"
      ],
      "metadata": {
        "id": "F4AdHAaTtIra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['source_documents'])"
      ],
      "metadata": {
        "id": "pY6ONL2GtKrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        " return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "iljNccQltMog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir templates -p"
      ],
      "metadata": {
        "id": "xvl2l7_ltOps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile templates/index.html\n",
        "\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "  <title>UTS Cafeteria GPT</title>\n",
        "  <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css\">\n",
        "  <style>\n",
        "    body {\n",
        "        background-image:  url(https://lh5.googleusercontent.com/p/AF1QipPr5YfZjO-FRPh9Xqv83eJ19l6Kl3CdOsAJ6t4-=w141-h118-n-k-no-nu);\n",
        "        background-color: rgba(0, 0, 0, 0.8);\n",
        "        background-repeat: no-repeat;\n",
        "        background-position: center;\n",
        "        background-attachment: fixed;\n",
        "        background-size: cover;\n",
        "        background-blend-mode: darken;\n",
        "      font-family: Arial, sans-serif;\n",
        "    }\n",
        "\n",
        "    .container {\n",
        "      max-width: 600px;\n",
        "      margin: 100px auto;\n",
        "      background-color: #fff;\n",
        "      border-radius: 8px;\n",
        "      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
        "      padding: 20px;\n",
        "    }\n",
        "\n",
        "    #chatContainer {\n",
        "      height: 600px;\n",
        "      overflow-y: auto;\n",
        "      border: 1px solid #ccc;\n",
        "      border-radius: 8px;\n",
        "      padding: 10px;\n",
        "      margin-bottom: 20px;\n",
        "      background-color: #f9f9f9;\n",
        "    }\n",
        "\n",
        "    .messageContainer {\n",
        "      margin-bottom: 10px;\n",
        "      overflow: hidden;\n",
        "    }\n",
        "\n",
        "    .message {\n",
        "      padding: 10px;\n",
        "      border-radius: 8px;\n",
        "      max-width: 80%;\n",
        "      word-wrap: break-word;\n",
        "    }\n",
        "\n",
        "    .userMessage {\n",
        "      background-color: #007bff;\n",
        "      color: #fff;\n",
        "      float: right;\n",
        "    }\n",
        "\n",
        "    .botMessage {\n",
        "      background-color: #28a745;\n",
        "      color: #fff;\n",
        "      float: left;\n",
        "    }\n",
        "\n",
        "    .avatar {\n",
        "      width: 30px;\n",
        "      height: 30px;\n",
        "      border-radius: 50%;\n",
        "      margin-right: 10px;\n",
        "      float: left;\n",
        "    }\n",
        "\n",
        "    .typingIndicator {\n",
        "      display: inline-block;\n",
        "      width: 10px;\n",
        "      height: 10px;\n",
        "      margin-right: 5px;\n",
        "      background-color: #ccc;\n",
        "      border-radius: 50%;\n",
        "      animation: typingAnimation 1s infinite;\n",
        "    }\n",
        "\n",
        "    @keyframes typingAnimation {\n",
        "      0% {\n",
        "        background-color: #ccc;\n",
        "      }\n",
        "      50% {\n",
        "        background-color: transparent;\n",
        "      }\n",
        "      100% {\n",
        "        background-color: #ccc;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    /* Style for form input and button */\n",
        "    .form-group {\n",
        "      display: flex;\n",
        "      align-items: center;\n",
        "    }\n",
        "\n",
        "    #question {\n",
        "      flex: 1;\n",
        "      margin-right: 10px;\n",
        "      padding: 8px;\n",
        "      border: 1px solid #ccc;\n",
        "      border-radius: 5px;\n",
        "    }\n",
        "\n",
        "    #submitBtn {\n",
        "      padding: 8px 20px;\n",
        "      background-color: #007bff;\n",
        "      color: #fff;\n",
        "      border: none;\n",
        "      border-radius: 5px;\n",
        "      cursor: pointer;\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"container\">\n",
        "  <h1 class=\"text-center\">Cafeteria GPT</h1>\n",
        "\n",
        "  <div id=\"chatContainer\"></div>\n",
        "\n",
        "  <form id=\"chatForm\" action=\"#\" method=\"POST\">\n",
        "    <div class=\"form-group\">\n",
        "      <input type=\"text\" id=\"question\" name=\"question\" placeholder=\"Type your message...\" autocomplete=\"off\">\n",
        "      <button type=\"submit\" id=\"submitBtn\">Send</button>\n",
        "    </div>\n",
        "  </form>\n",
        "</div>\n",
        "\n",
        "<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js\"></script>\n",
        "<script>\n",
        "  $(document).ready(function() {\n",
        "    // 定义一个基类\n",
        "    function ChatMessage(content, isUser) {\n",
        "      this.content = content;\n",
        "      this.isUser = isUser;\n",
        "    }\n",
        "\n",
        "    // Polymorphism:Method defined in ChatMessage (添加一个方法到 ChatMessage 的原型上，用于展示消息)\n",
        "    ChatMessage.prototype.displayMessage = function() {\n",
        "      var messageClass = this.isUser ? \"userMessage\" : \"botMessage\";\n",
        "      var messageContent = \"<div class='message \" + messageClass + \"'>\" + this.content + \"</div>\";\n",
        "      var avatar = this.isUser ? \"\" : \"<img src='https://cdn-icons-png.flaticon.com/512/4712/4712109.png' class='avatar'>\";\n",
        "      return \"<div class='messageContainer'>\" + avatar + messageContent + \"</div>\";\n",
        "    };\n",
        "\n",
        "    // Inheritance:UserMessage inherits from ChatMessage (派生一个具体类，继承自基类 ChatMessage)\n",
        "    function UserMessage(content) {\n",
        "      ChatMessage.call(this, content, true);\n",
        "    }\n",
        "\n",
        "    // Inheritance:UserMessage inherits from ChatMessage (使用原型链继承基类的方法)\n",
        "    UserMessage.prototype = Object.create(ChatMessage.prototype);\n",
        "    UserMessage.prototype.constructor = UserMessage;\n",
        "\n",
        "    // Inheritance:BotMessage inherits from ChatMessage (派生一个具体类，继承自基类 ChatMessage)\n",
        "    function BotMessage(content) {\n",
        "      ChatMessage.call(this, content, false);\n",
        "    }\n",
        "\n",
        "    // Inheritance:BotMessage inherits from ChatMessage (使用原型链继承基类的方法)\n",
        "    BotMessage.prototype = Object.create(ChatMessage.prototype);\n",
        "    BotMessage.prototype.constructor = BotMessage;\n",
        "\n",
        "    // 创建一个聊天界面类，用于处理用户输入和显示消息\n",
        "    function ChatInterface() {\n",
        "      this.messages = [];\n",
        "    }\n",
        "\n",
        "    ChatInterface.prototype.sendMessage = function(message) {\n",
        "      var userMessage = new UserMessage(message.trim()); // Objects:Creating an instance of UserMessage\n",
        "      this.messages.push(userMessage);\n",
        "      this.displayMessages();\n",
        "      // 模拟机器人回复\n",
        "      this.showTypingIndicator();\n",
        "      var that = this;\n",
        "      $.ajax({\n",
        "        url: '/get_response', // 将此 URL 替换为后端路由，用于获取机器人的回复消息\n",
        "        type: 'POST',\n",
        "        data: { question: message },\n",
        "        success: function(response) {\n",
        "          that.botReply(response);\n",
        "        },\n",
        "        error: function(xhr, status, error) { //exception handling\n",
        "          console.error(\"Error:\", error);\n",
        "          that.botReply(\"Sorry, Got Some Error, Please press f12 to check the error\")\n",
        "        }\n",
        "      });\n",
        "    };\n",
        "\n",
        "    ChatInterface.prototype.botReply = function(response) {\n",
        "      var botMessage = new BotMessage(response); // Objects:Creating an instance of BotMessage\n",
        "      // 移除等待特效\n",
        "      this.messages.pop();\n",
        "      this.messages.push(botMessage);\n",
        "      this.displayMessages();\n",
        "    };\n",
        "\n",
        "    ChatInterface.prototype.showTypingIndicator = function() {\n",
        "      var typingIndicator = \"<span class='typingIndicator'></span><span class='typingIndicator'></span><span class='typingIndicator'></span>\";\n",
        "      var botMessage = new BotMessage(typingIndicator);\n",
        "      this.messages.push(botMessage);\n",
        "      this.displayMessages();\n",
        "    };\n",
        "\n",
        "    ChatInterface.prototype.displayMessages = function() {\n",
        "      var chatContainer = $(\"#chatContainer\");\n",
        "      chatContainer.empty();\n",
        "      this.messages.forEach(function(message) {\n",
        "        chatContainer.append(message.displayMessage()); // Polymorphism:Using displayMessage in ChatInterface for both UserMessage and BotMessage\n",
        "      });\n",
        "      scrollChatContainer();\n",
        "    };\n",
        "\n",
        "    // 滚动聊天容器到底部\n",
        "    function scrollChatContainer() {\n",
        "      var chatContainer = $(\"#chatContainer\");\n",
        "      chatContainer.scrollTop(chatContainer.prop(\"scrollHeight\"));\n",
        "    }\n",
        "\n",
        "    // 创建一个聊天界面实例\n",
        "    var chatInterface = new ChatInterface();\n",
        "\n",
        "    // 初始问候消息\n",
        "    var initialGreeting = \"Hello and Welcome to Cafeteria Chatbot! What can I do for you?\";\n",
        "    var botMessage = new BotMessage(initialGreeting);\n",
        "    chatInterface.messages.push(botMessage);\n",
        "    chatInterface.displayMessages();\n",
        "\n",
        "    // 监听表单提交事件\n",
        "    $(\"#chatForm\").submit(function(event) {\n",
        "      event.preventDefault();\n",
        "      var userInput = $(\"#question\").val();\n",
        "      if (userInput) {\n",
        "        chatInterface.sendMessage(userInput);\n",
        "        $(\"#question\").val(\"\");\n",
        "      }\n",
        "    });\n",
        "\n",
        "    // Handle constant responses for specific user inputs\n",
        "    $(\"#chatForm\").on(\"input\", function() {\n",
        "      var userInput = $(\"#question\").val().toLowerCase();\n",
        "      if (lowerCaseMessage.includes('hello') || lowerCaseMessage.includes('hi')) {\n",
        "          return 'Hello! How can I assist you?';\n",
        "      } else if (lowerCaseMessage.includes('help')) {\n",
        "            return 'Sure, I can help you. What do you need assistance with?';\n",
        "      } else if (lowerCaseMessage.includes('bye') || lowerCaseMessage.includes('goodbye')) {\n",
        "            return 'Goodbye! Have a great day!';\n",
        "      } else {\n",
        "            return \"I'm sorry, I didn't understand that. Can you please rephrase?\";\n",
        "      }\n",
        "    });\n",
        "\n",
        "  });\n",
        "</script>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KFv-MISktQ3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading"
      ],
      "metadata": {
        "id": "BV-U0McotV9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "jl7FdLiytXn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!killall ngrok"
      ],
      "metadata": {
        "id": "TsYgHDsXtZc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "!ngrok version\n",
        "os.environ[\"FLASK_DEBUG\"] = \"development\"\n",
        "# template_folder = '/gdrive/MyDrive/AIWeb/template'\n",
        "app = Flask(__name__)\n",
        "port = 5000\n",
        "ngrok.set_auth_token(\"ngroktoken_id\")\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\"* ngrok tunnel \\\"{}\\\">\\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n",
        "\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "message = \"\"\n",
        "question = \"\"\n",
        "questionArray = []\n",
        "chat_history = []\n",
        "@app.route(\"/\")\n",
        "@app.route(\"/index\", methods=['GET', 'POST'])\n",
        "def index():\n",
        "  global message\n",
        "  global question\n",
        "  # global questionArray\n",
        "  if request.method == 'POST':\n",
        "    # chat_history = [(query, result[\"answer\"])]\n",
        "    # question = request.form.get(\"question\")\n",
        "    getQuestion = request.form.get(\"question\")\n",
        "    result = chain({\"question\": getQuestion, \"chat_history\": chat_history})\n",
        "    question = getQuestion\n",
        "    message = result['answer']\n",
        "    # questionArray.append()\n",
        "    # print(result)\n",
        "    # print(chat_history)\n",
        "  return render_template('index.html', message=message, question=question)\n",
        "@app.route('/get_response', methods=['POST'])\n",
        "def get_response():\n",
        "    user_question = request.form['question']\n",
        "    result = chain({\"question\": user_question, \"chat_history\": chat_history})\n",
        "    bot_response = result['answer']\n",
        "    return bot_response\n",
        "threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()"
      ],
      "metadata": {
        "id": "A_s76BsNtbCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "smv_2Up8td9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "from pyngrok import ngrok\n",
        "!ngrok version\n",
        "os.environ[\"FLASK_ENV\"] = \"development\"\n",
        "template_folder = '/gdrive/MyDrive/AIWeb/template'\n",
        "app = Flask(__name__,template_folder=template_folder)\n",
        "port = 5000\n",
        "ngrok.set_auth_token(\"ngroktoken_id\")\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\"* ngrok tunnel \\\"{}\\\">\\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n",
        "\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "\n",
        "@app.route(\"/\", methods=['GET', 'POST'])\n",
        "@app.route(\"/index\", methods=['GET', 'POST'])\n",
        "def index():\n",
        "  global message\n",
        "  if request.method == 'POST':\n",
        "    chat_history = [(question, result[\"answer\"])]\n",
        "    question = request.form.get(\"question\")\n",
        "    # query = request.form.get(\"question\")\n",
        "    result = chain({\"question\": question, \"chat_history\": chat_history})\n",
        "    message = result['answer']\n",
        "    print(result['answer'])\n",
        "    # print(chat_history)\n",
        "  return render_template('index.html', message=message)\n",
        "threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()"
      ],
      "metadata": {
        "id": "x9gY_Jy-tf9Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}